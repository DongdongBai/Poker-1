// Implementation of Local Best Response calculation for a lower bound on
// exploitability from https://arxiv.org/abs/1612.07547

// I'm using the "fcpa" (fold, call, pot, all-in) action choices from the paper, which is
// way faster and still gives decent results. I'm also having the exploiter
// check/call on the preflop and flop.

// Right now: Sanity check with chump strategies, like always call.

use crate::card_utils;
use crate::card_utils::Card;
use crate::trainer_utils::*;
use std::collections::HashMap;
use rand::seq::SliceRandom;
use bio::stats::combinatorics::combinations;
use itertools::Itertools;

const ITERS: i32 = 100;

// TODO: Instead of taking in a HashMap<InfoSet, Node> table of strategies, pass
// in a "bot" instance where you give it an infoset and it gives you a strategy or action
pub fn exploitability(strategy: &HashMap<InfoSet, Node>) -> f64 {
    println!("[INFO] Calculating exploitability...");
    let mut exploits = Vec::new();
    for i in 0..ITERS {
        let e = (play_hand(strategy) as f64) / (BIG_BLIND as f64);
        exploits.push(e);
    }
    let mean = statistical::mean(&exploits);
    let std = statistical::standard_deviation(&exploits, Some(mean));
    let confidence = 1.96 * std / (ITERS as f64).sqrt();
    println!("Exploitability: {} +/- {} BB/h", mean, confidence);
    mean
}

fn play_hand(strategy: &HashMap<InfoSet, Node>) -> i32 {
    let mut deck = card_utils::deck();
    let mut rng = &mut rand::thread_rng();
    deck.shuffle(&mut rng);
    let exploiter = [DEALER, OPPONENT].choose(&mut rng).unwrap().clone();
    let opponent = 1 - exploiter;
    let mut opp_range = construct_opponent_range(&deck, exploiter);
    let mut history = ActionHistory::new();

    while !history.hand_over() {
        remove_blockers(&mut opp_range, &deck, history.street.clone());
        if history.player == exploiter {
            let action = local_best_response(strategy, &opp_range, &history, &deck);
            history.add(&action);
            if action == FOLD {
                return history.stack_sizes()[exploiter] - STACK_SIZE;
            }
        } else {
            let infoset = InfoSet::from_deck(&deck, &history);
            // TODO: What if the current infoset isn't present in the strategy?
            // Probably just sample uniformly from possible actions, but there
            // should be some sort of warning/error to train for more iterations
            // let node = strategy.get(&infoset).unwrap();
            // let action = sample_action(&node);
            // update_range(&mut opp_range, &node);
            // Chump strategy: always call
            let action = Action { action: ActionType::Call, amount: history.to_call()};
            history.add(&action);

            if action == FOLD {
                return STACK_SIZE - history.stack_sizes()[opponent];
            }
        }
    }
    terminal_utility(&deck, history, exploiter);
    let utils = showdown(&deck);
    return utils;
}

fn showdown(deck: &[Card]) -> i32 {
    unimplemented!();
}

fn update_range(range: &mut HashMap<Vec<Card>, f64>, node: &Node) {
    unimplemented!();
}

fn construct_opponent_range(deck: &[Card], exploiter: usize) -> HashMap<Vec<Card>, f64> {
    let mut range = HashMap::new();
    let exploiter_hole = get_hand(deck, exploiter, PREFLOP);
    // Remove the exploiter's preflop hand from the range since the opponent
    // can't have the exploiter's cards
    let mut deck = deck.to_vec();
    deck.retain(|c| !exploiter_hole.contains(&c));
    for hand in deck.iter().combinations(2) {
        let hand = card_utils::deepcopy(&hand);
        range.insert(hand, 1.0);
    }
    normalize(&mut range);
    range
}

fn remove_blockers(opp_range: &mut HashMap<Vec<Card>, f64>, board: &[Card], street: usize) {
    unimplemented!();
    // TODO: Should I normalize the range at the end of this?
}

fn local_best_response(strategy: &HashMap<InfoSet, Node>, opp_range: &HashMap<Vec<Card>, f64>, history: &ActionHistory, deck: &[Card]) -> Action {
    unimplemented!();
}
